{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2ba6549-8b15-4f95-9615-549dd5fa2f7c",
      "metadata": {
        "id": "d2ba6549-8b15-4f95-9615-549dd5fa2f7c"
      },
      "source": [
        "### Lab: Value Iteration in a Grid World\n",
        "\n",
        "### University of Virginia\n",
        "### Reinforcement Learning\n",
        "#### Last updated: December 11, 2023\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2afeab41-bd5f-40e8-ad2f-e8999f13ed45",
      "metadata": {
        "id": "2afeab41-bd5f-40e8-ad2f-e8999f13ed45"
      },
      "source": [
        "#### Instructions:\n",
        "\n",
        "Implement value iteration for a $4 \\times 3$ gridworld environment. This will measure the value of each state. A robot in this world can make discrete moves: one step up, down, left or right. These actions are deterministic, meaning that the action selected will be taken with probability 1. There is a terminal state with reward +1 in the bottom right corner. All other states have reward 0. The discount factor is 0.9. Use tolerance $\\theta=0.01$. Show all code and results.\n",
        "\n",
        "**Note**: Do not use libraries from `networkx`, `gym`, `gymnasium` when solving this problem.\n",
        "\n",
        "#### Total Points: 12"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5956322-1af2-4a18-b65c-d98dc08454c8",
      "metadata": {
        "id": "a5956322-1af2-4a18-b65c-d98dc08454c8"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1) **(POINTS: 2)** As part of your solution, create a GridWorld class with these attributes:\n",
        "\n",
        "- `nrows` : number of rows in the grid\n",
        "- `ncols` : number of columns in the grid\n",
        "\n",
        "and these methods:\n",
        "\n",
        "- `value_iteration()` with behavior described in [2] below\n",
        "- `get_reward()` : given the agent row and column, return the reward\n",
        "\n",
        "The class may include additional attributes and methods as well.\n",
        "\n",
        "Create an instance using the class, and call `nrows`, `ncols`, and `get_reward()` to verify correctness.\n",
        "\n",
        "You will not be graded on the implementation of `value_iteration()` for this problem.\n",
        "\n",
        "#### 2) **(POINTS: 8)** Here, you will be graded on the implementation of `value_iteration()`.\n",
        "Call `value_iteration()` to calculate and return the value function array. For each sweep over the states, have the function print out the intermediate array.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd213107-d461-431c-b1e1-d1d3c099976d",
      "metadata": {
        "id": "bd213107-d461-431c-b1e1-d1d3c099976d"
      },
      "source": [
        "#### Enter all code here (you may also use multiple cells)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "338948a3-db77-4458-a6ed-a3f5e4aa3c72",
      "metadata": {
        "id": "338948a3-db77-4458-a6ed-a3f5e4aa3c72"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "858c5f68-7b54-459e-95f3-59697cfa6d23",
      "metadata": {
        "id": "858c5f68-7b54-459e-95f3-59697cfa6d23"
      },
      "source": [
        "#### 1) Create and test the class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a21a43af-2be7-49d3-aec0-1934160bb61c",
      "metadata": {
        "id": "a21a43af-2be7-49d3-aec0-1934160bb61c"
      },
      "outputs": [],
      "source": [
        "class GridWorld():\n",
        "    def __init__(self, nrows, ncols):\n",
        "        self.nrows = nrows\n",
        "        self.ncols = ncols\n",
        "        self.values = np.zeros((nrows, ncols))\n",
        "        self.actions = ['up', 'down', 'left', 'right']\n",
        "\n",
        "    def value_iteration(self, theta=0.01, discount_factor=0.9, max_iter = 100):\n",
        "      while True:\n",
        "        delta = 0\n",
        "        v = np.copy(self.values)\n",
        "        for i in range(self.nrows):\n",
        "          for j in range(self.ncols):\n",
        "            if i == self.nrows - 1 and j == self.ncols - 1:\n",
        "              continue\n",
        "            else:\n",
        "              max_value = -np.inf\n",
        "              v[i,j] = np.max(v, )\n",
        "              delta = max(delta, abs(v[i,j] - self.values[i,j]))\n",
        "        self.values = v\n",
        "        if delta < theta:\n",
        "          break\n",
        "        elif max_iter == 0:\n",
        "          break\n",
        "        else:\n",
        "          max_iter -= 1\n",
        "          print(self.values)\n",
        "\n",
        "      return self.values\n",
        "\n",
        "    def get_reward(self, row, col):\n",
        "        if row == self.nrows - 1 and col == self.ncols - 1:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gw = GridWorld(4, 3)\n",
        "print(gw.nrows)\n",
        "print(gw.ncols)\n",
        "print(gw.get_reward(0, 0))\n",
        "print(gw.get_reward(2, 1))\n",
        "print(gw.get_reward(3, 2))"
      ],
      "metadata": {
        "id": "dx8ZriYQgn87",
        "outputId": "b2d0d1c2-73e5-4e98-de99-20a43ee33953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dx8ZriYQgn87",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "3\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb15497-6f08-4f3e-abef-43099f05fba7",
      "metadata": {
        "id": "dfb15497-6f08-4f3e-abef-43099f05fba7"
      },
      "source": [
        "#### 2) Run value iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "922da11f-c12f-4535-8a8a-63cbcab3e736",
      "metadata": {
        "id": "922da11f-c12f-4535-8a8a-63cbcab3e736",
        "outputId": "7d84397c-e822-47e1-a711-1597046ab6d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "gw.value_iteration(max_iter=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "486efc92-9a71-4956-b877-b6b7cef13031",
      "metadata": {
        "id": "486efc92-9a71-4956-b877-b6b7cef13031"
      },
      "source": [
        "#### 3) **(POINTS: 2)** Based on the value function: After the agent has moved right or down, does it ever make sense for it to backtrack (move up or left)? Explain your reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f4d310a-493c-4bcc-8328-c09c88116b0e",
      "metadata": {
        "id": "5f4d310a-493c-4bcc-8328-c09c88116b0e"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}