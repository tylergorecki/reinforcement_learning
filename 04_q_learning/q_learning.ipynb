{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy8PeIwuppNs"
      },
      "source": [
        "### Q-Learning\n",
        "\n",
        "### University of Virginia\n",
        "### Reinforcement Learning\n",
        "#### Last updated: February 4, 2025\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeW_5UTappNt"
      },
      "source": [
        "\n",
        "### SOURCES\n",
        "\n",
        "- Reinforcement Learning, RS Sutton & AG Barto, 2nd edition. Chapter 6\n",
        "- Mastering Reinforcement Learning with Python, Enes Bilgin. Chapter 5\n",
        "\n",
        "### LEARNING OUTCOMES\n",
        "\n",
        "- Explain how Q-Learning works and how it learns off policy\n",
        "- Use Q-Learning to compute value functions  \n",
        "- Perform sensitivity analysis on a Q-Learning algorithm\n",
        "- Check for algorithm convergence\n",
        "\n",
        "### CONCEPTS\n",
        "\n",
        "- Q-Learning to act off policy\n",
        "- The Q-Learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivaivd6VppNt"
      },
      "source": [
        "---  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n8Quwj8ppNt"
      },
      "source": [
        "### I. Q-table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFj9K61QppNt"
      },
      "source": [
        "We recall the big picture of what we're trying to do:  \n",
        "Given state space $S$ and action space $A$, learn values $Q(S,A)$  \n",
        "These are organized in an array called the *Q-table*.\n",
        "\n",
        "Q-Learning is a method for building this table.\n",
        "\n",
        "We initialize the table (zeros, random values with zeros at terminal condition, etc.) and then use TD(0) updates for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYosKMUVppNt"
      },
      "source": [
        "<img src=\"https://github.com/tylergorecki/reinforcement_learning/blob/main/04_q_learning/Q-Learning_Matrix_Initialized_and_After_Training.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFtKOWr0ppNt"
      },
      "source": [
        "### II. Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VHVis7GppNt"
      },
      "source": [
        "Q-Learning is an **off-policy TD control algorithm** that was an early breakthrough in RL.\n",
        "\n",
        "Quick reminder of what off-policy means:\n",
        "\n",
        "We want action-value estimates. To make improvements requires exploring. These two things are at odds.\n",
        "\n",
        "Consider: You're looking for a faster route to work. If you try different routes, some will be slower.  \n",
        "These slower routes shouldn't factor into the timing of the optimal route. You separate optimal route timing from exploration.\n",
        "\n",
        "We do this by maintaining two policies:\n",
        "- behavior policy for learning\n",
        "- target policy for learning optimality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBZWDAHkppNu"
      },
      "source": [
        "Now we show the update equation for improving $q_\\pi(s,a)$  \n",
        "It is very similar to the update step for the state value.\n",
        "\n",
        "Since we will use sample data, $Q$ will denote estimates of $q_\\pi$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zrEYl_QppNu"
      },
      "source": [
        "$Q(s,a) := Q(s,a) + \\alpha [r + \\gamma \\underset{a}{\\operatorname{\\max}} Q(s',a) -  Q(s,a)]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beIOvfoSppNu"
      },
      "source": [
        "Explaining the different components:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfVBaHXgppNu"
      },
      "source": [
        "<img src=\"https://github.com/tylergorecki/reinforcement_learning/blob/main/04_q_learning/q_learning_update.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRH8D9RUppNu"
      },
      "source": [
        "An important difference is the $\\underset{a}{\\operatorname{\\max}} Q(s',a)$ term where you might have expected $Q(s',a)$  \n",
        "\n",
        "The agent computes the most valuable action and uses this in updating.\n",
        "\n",
        "However, the agent many not actually take this step when $S_{t+1}=s'$, $A_{t+1}=a$\n",
        "\n",
        "This is what it means to act off policy: the target policy is separated from the behavior policy.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSSdpW4LppNu"
      },
      "source": [
        "**Septic Shock**\n",
        "\n",
        "Next, let's look at a computational example. The objective is to reduce the chance of septic shock, measured by the proxy SOFA score, by using a drug called a vasopressor. The values are for illustration only. Following the code are a series of exercises that we will work through.\n",
        "\n",
        "Background:  \n",
        "- **Septic shock**: a life-threatening condition that happens when blood pressure drops to a dangerously low level after an infection\n",
        "- **Sequential Organ Failure Assessment (SOFA) score** is a scoring system that assesses the performance of several organ systems in the body. We will use this to measure state. Higher is more dangerous.\n",
        "- **Vasopressor (vaso)** a drug that healthcare providers use to make blood vessels constrict (raising blood pressure) in patients with low blood pressure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "0oY_McUpppNu",
        "outputId": "c7b09185-84ea-4f41-c604-e952a41dea0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 1\n",
            "Q \n",
            " [[ 0.899 -0.841  0.124  0.115  73.654]\n",
            " [-1.387 -2.533 -0.223 -0.498  21.655]\n",
            " [-0.308 -0.561 -0.884  3.142 -1.468]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 11\n",
            "Q \n",
            " [[ 177.852  106.359  256.306  333.157  613.237]\n",
            " [-1.387  33.445 -0.223 -0.498  513.998]\n",
            " [-0.308  0.402 -0.884  288.677 -1.468]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 21\n",
            "Q \n",
            " [[ 591.598  483.616  666.731  688.652  833.767]\n",
            " [ 107.298  33.445  60.161 -0.498  808.378]\n",
            " [-0.308  63.157 -0.884  673.190  71.531]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 31\n",
            "Q \n",
            " [[ 833.754  735.167  823.742  861.186  928.481]\n",
            " [ 175.198  114.271  143.179 -0.498  916.893]\n",
            " [-0.308  146.893  77.833  851.115  71.531]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 41\n",
            "Q \n",
            " [[ 939.741  879.561  906.340  946.215  968.261]\n",
            " [ 366.542  196.750  223.344  92.763  965.345]\n",
            " [-10.277  146.893  231.209  937.975  236.161]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 51\n",
            "Q \n",
            " [[ 963.081  938.100  949.304  970.955  986.426]\n",
            " [ 423.841  196.750  357.800  260.472  984.188]\n",
            " [-19.249  228.243  231.209  963.685  308.985]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 61\n",
            "Q \n",
            " [[ 978.562  955.574  970.528  986.591  994.195]\n",
            " [ 477.069  196.750  524.666  398.831  993.476]\n",
            " [-19.249  303.129  231.209  978.663  308.985]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 71\n",
            "Q \n",
            " [[ 984.086  970.492  969.192  994.074  997.240]\n",
            " [ 525.766  408.422  524.666  398.831  996.678]\n",
            " [-34.592  303.129  231.209  984.908  376.562]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 81\n",
            "Q \n",
            " [[ 986.720  975.524  968.575  997.363  998.763]\n",
            " [ 525.766  466.428  524.666  458.731  998.528]\n",
            " [-41.133  303.129  306.862  987.559  437.758]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 91\n",
            "Q \n",
            " [[ 988.820  977.714  977.945  998.901  999.469]\n",
            " [ 609.806  518.672  524.666  512.770  999.385]\n",
            " [-41.133  303.129  306.862  988.970  437.758]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 101\n",
            "Q \n",
            " [[ 989.522  981.100  981.564  999.587  999.773]\n",
            " [ 645.742  518.672  571.157  605.277  999.726]\n",
            " [-41.133  303.129  375.123  989.462  437.758]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 111\n",
            "Q \n",
            " [[ 989.774  979.856  977.677  999.830  999.904]\n",
            " [ 678.147  565.782  613.015  680.245  999.881]\n",
            " [-41.133  303.129  434.577  989.793  437.758]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 121\n",
            "Q \n",
            " [[ 989.910  978.600  979.943  999.917  999.958]\n",
            " [ 707.329  608.198  680.833  680.245  999.949]\n",
            " [-47.020  429.830  434.577  989.902  437.758]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 131\n",
            "Q \n",
            " [[ 989.963  977.927  980.503  999.969  999.982]\n",
            " [ 757.245  644.385  680.833  712.219  999.979]\n",
            " [-47.020  429.830  434.577  989.965  437.758]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 141\n",
            "Q \n",
            " [[ 989.985  974.422  984.752  999.986  999.992]\n",
            " [ 797.683  708.257  680.833  740.995  999.991]\n",
            " [-47.020  429.830  434.577  989.984  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 151\n",
            "Q \n",
            " [[ 989.993  980.262  981.326  999.994  999.997]\n",
            " [ 797.683  782.617  680.833  740.995  999.996]\n",
            " [-47.020  483.856  488.128  989.994  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 161\n",
            "Q \n",
            " [[ 989.997  978.217  980.328  999.997  999.999]\n",
            " [ 797.683  852.144  737.584  811.185  999.998]\n",
            " [-47.020  483.856  488.128  989.997  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 171\n",
            "Q \n",
            " [[ 989.999  980.976  983.388  999.999  999.999]\n",
            " [ 830.442  863.940  804.197  830.066  999.999]\n",
            " [-47.020  483.856  488.128  989.999  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 181\n",
            "Q \n",
            " [[ 989.999  976.877  979.151  1000.000  1000.000]\n",
            " [ 856.977  863.940  820.788  847.060  1000.000]\n",
            " [-47.020  483.856  488.128  990.000  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 191\n",
            "Q \n",
            " [[ 990.000  979.007  979.285  1000.000  1000.000]\n",
            " [ 895.880  863.940  849.157  847.060  1000.000]\n",
            " [-47.020  534.470  488.128  990.000  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 201\n",
            "Q \n",
            " [[ 990.000  980.837  978.241  1000.000  1000.000]\n",
            " [ 895.880  874.556  863.241  847.060  1000.000]\n",
            " [-47.020  534.470  488.128  990.000  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 211\n",
            "Q \n",
            " [[ 990.000  977.742  978.782  1000.000  1000.000]\n",
            " [ 895.880  884.110  895.802  876.118  1000.000]\n",
            " [-47.020  534.470  488.128  990.000  492.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 221\n",
            "Q \n",
            " [[ 990.000  976.926  979.538  1000.000  1000.000]\n",
            " [ 903.302  911.194  919.718  888.506  1000.000]\n",
            " [-47.020  534.470  488.128  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 231\n",
            "Q \n",
            " [[ 990.000  980.980  981.658  1000.000  1000.000]\n",
            " [ 909.982  917.085  919.718  899.656  1000.000]\n",
            " [-47.020  534.470  488.128  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 241\n",
            "Q \n",
            " [[ 990.000  982.585  979.737  1000.000  1000.000]\n",
            " [ 915.993  935.054  924.756  899.656  1000.000]\n",
            " [-47.020  534.470  538.316  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 251\n",
            "Q \n",
            " [[ 990.000  977.360  981.560  1000.000  1000.000]\n",
            " [ 926.274  940.549  940.646  909.690  1000.000]\n",
            " [-47.020  534.470  538.316  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 261\n",
            "Q \n",
            " [[ 990.000  976.771  982.320  1000.000  1000.000]\n",
            " [ 926.274  940.549  943.591  926.849  1000.000]\n",
            " [-47.020  534.470  538.316  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 271\n",
            "Q \n",
            " [[ 990.000  978.050  979.441  1000.000  1000.000]\n",
            " [ 930.656  945.494  943.591  926.849  1000.000]\n",
            " [-47.020  580.023  581.494  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 281\n",
            "Q \n",
            " [[ 990.000  979.301  984.205  1000.000  1000.000]\n",
            " [ 938.151  945.494  946.242  934.164  1000.000]\n",
            " [-52.318  619.031  581.494  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 291\n",
            "Q \n",
            " [[ 990.000  979.120  977.524  1000.000  1000.000]\n",
            " [ 941.346  955.943  950.775  934.164  1000.000]\n",
            " [-52.318  619.031  688.597  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 301\n",
            "Q \n",
            " [[ 990.000  979.051  983.354  1000.000  1000.000]\n",
            " [ 941.346  959.349  954.698  946.673  1000.000]\n",
            " [-52.318  619.031  716.748  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 311\n",
            "Q \n",
            " [[ 990.000  977.228  981.362  1000.000  1000.000]\n",
            " [ 941.346  962.414  954.698  952.006  1000.000]\n",
            " [-52.318  619.031  744.073  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 321\n",
            "Q \n",
            " [[ 990.000  984.066  983.435  1000.000  1000.000]\n",
            " [ 944.221  962.414  956.238  952.006  1000.000]\n",
            " [-57.086  619.031  744.073  990.000  542.683]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 331\n",
            "Q \n",
            " [[ 990.000  977.196  976.438  1000.000  1000.000]\n",
            " [ 951.234  965.172  956.238  961.125  1000.000]\n",
            " [-61.377  619.031  744.073  990.000  587.415]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 341\n",
            "Q \n",
            " [[ 990.000  980.817  979.846  1000.000  1000.000]\n",
            " [ 954.819  965.665  959.614  965.012  1000.000]\n",
            " [-61.377  619.031  744.073  990.000  587.415]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 351\n",
            "Q \n",
            " [[ 990.000  978.750  982.969  1000.000  1000.000]\n",
            " [ 956.347  968.099  959.614  971.660  1000.000]\n",
            " [-61.377  689.515  744.073  990.000  587.415]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 361\n",
            "Q \n",
            " [[ 990.000  984.181  976.874  1000.000  1000.000]\n",
            " [ 956.347  968.299  959.614  974.494  1000.000]\n",
            " [-61.377  689.515  744.073  990.000  627.673]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 371\n",
            "Q \n",
            " [[ 990.000  980.837  981.063  1000.000  1000.000]\n",
            " [ 957.722  968.299  967.849  979.340  1000.000]\n",
            " [-61.377  689.515  744.073  990.000  663.906]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 381\n",
            "Q \n",
            " [[ 990.000  982.857  979.314  1000.000  1000.000]\n",
            " [ 958.960  968.299  968.074  981.406  1000.000]\n",
            " [-61.377  717.574  744.073  990.000  696.515]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 391\n",
            "Q \n",
            " [[ 990.000  977.548  980.551  1000.000  1000.000]\n",
            " [ 960.074  970.631  968.074  983.265  1000.000]\n",
            " [-61.377  717.574  744.073  990.000  725.864]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 401\n",
            "Q \n",
            " [[ 990.000  976.386  982.225  1000.000  1000.000]\n",
            " [ 961.077  972.520  970.266  984.939  1000.000]\n",
            " [-61.377  717.574  789.008  990.000  725.864]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 411\n",
            "Q \n",
            " [[ 990.000  981.163  977.818  1000.000  1000.000]\n",
            " [ 961.979  972.520  970.235  984.939  1000.000]\n",
            " [-61.377  717.574  807.117  990.000  776.050]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 421\n",
            "Q \n",
            " [[ 990.000  981.378  979.670  1000.000  1000.000]\n",
            " [ 962.791  974.268  970.235  984.939  1000.000]\n",
            " [-61.377  717.574  807.117  990.000  797.445]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 431\n",
            "Q \n",
            " [[ 990.000  980.789  980.638  1000.000  1000.000]\n",
            " [ 963.522  974.268  972.211  986.445  1000.000]\n",
            " [-61.377  717.574  807.117  990.000  797.445]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 441\n",
            "Q \n",
            " [[ 990.000  982.916  976.576  1000.000  1000.000]\n",
            " [ 964.180  975.841  972.211  987.800  1000.000]\n",
            " [-61.377  717.574  823.415  990.000  849.627]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 451\n",
            "Q \n",
            " [[ 990.000  981.960  977.951  1000.000  1000.000]\n",
            " [ 964.180  975.841  975.042  991.107  1000.000]\n",
            " [-61.377  717.574  823.415  990.000  849.627]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 461\n",
            "Q \n",
            " [[ 990.000  985.105  980.700  1000.000  1000.000]\n",
            " [ 966.216  974.750  977.484  991.996  1000.000]\n",
            " [-65.240  791.401  838.084  990.000  863.664]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 471\n",
            "Q \n",
            " [[ 990.000  975.975  978.737  1000.000  1000.000]\n",
            " [ 966.604  975.480  977.901  992.796  1000.000]\n",
            " [-65.240  827.145  838.084  990.000  876.298]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 481\n",
            "Q \n",
            " [[ 990.000  977.258  980.609  1000.000  1000.000]\n",
            " [ 966.954  974.458  977.121  992.796  1000.000]\n",
            " [-68.716  841.440  853.276  990.000  876.298]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 491\n",
            "Q \n",
            " [[ 990.000  983.436  978.316  1000.000  1000.000]\n",
            " [ 966.954  974.458  978.820  992.796  1000.000]\n",
            " [-71.844  841.440  853.276  990.000  887.668]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
        "\n",
        "# Initialize states, actions, Q function\n",
        "\n",
        "# states\n",
        "sofa_levels = [0,1,2,3]\n",
        "num_states = len(sofa_levels)\n",
        "terminal_state = 3\n",
        "\n",
        "# actions\n",
        "vaso_dose = [0,1,2,3,4]\n",
        "num_actions = len(vaso_dose)\n",
        "\n",
        "# initialize array to store action values Q\n",
        "Q = np.random.normal(size=(num_states, num_actions))\n",
        "Q[terminal_state,:] = 0 # no action taken from terminal state, so no value\n",
        "\n",
        "\n",
        "def act(epsilon, action_values):\n",
        "    '''\n",
        "    epsilon-greedy policy: return action using epsilon-greedy strategy\n",
        "    '''\n",
        "    action_size = len(action_values)\n",
        "    if np.random.rand() <= epsilon: # random draw with prob epsilon\n",
        "        return random.randrange(action_size)\n",
        "    return np.argmax(action_values)  # returns action\n",
        "\n",
        "def calc_reward(state):\n",
        "    '''\n",
        "    simple reward function for illustration. lower state value is better\n",
        "    '''\n",
        "    if state == 3:\n",
        "        reward = -100\n",
        "    elif state == 2:\n",
        "        reward = -10\n",
        "    elif state == 1:\n",
        "        reward = 0\n",
        "    else:\n",
        "        reward = 10\n",
        "    return reward\n",
        "\n",
        "def determine_next_state(state, action):\n",
        "    '''\n",
        "    return next state from the environment\n",
        "    to be replaced with simulated data or alternative\n",
        "    '''\n",
        "    if (state in [0,1,2]) & (action == 0): # no dose raises state\n",
        "        next_state = min(terminal_state, state + 1)\n",
        "    elif action in [3,4]: # higher doses lowers state (floored at zero)\n",
        "        next_state = max(0, state - 1)\n",
        "    else:\n",
        "        next_state = random.choice([1,2])\n",
        "    return next_state\n",
        "\n",
        "# Run the Process\n",
        "num_episodes = 500\n",
        "max_timesteps = 100\n",
        "epsilon = 0.1\n",
        "alpha = 0.1 # weight on new data\n",
        "gamma = 0.99 # discount factor\n",
        "verbose = False\n",
        "\n",
        "for ep in range(num_episodes):\n",
        "    if ep % 10 == 0:\n",
        "        print('episode',ep+1)\n",
        "    #print('(state,action,reward,next_state) transitions')\n",
        "    sofa_level = 0 # initialize state\n",
        "    done = False\n",
        "    for tm in range(max_timesteps):\n",
        "\n",
        "        # given state, get action from policy\n",
        "        vaso_dose = act(epsilon, Q[sofa_level,:])\n",
        "\n",
        "        next_sofa = determine_next_state(sofa_level, vaso_dose)\n",
        "        reward = calc_reward(next_sofa)\n",
        "        transition = (sofa_level,vaso_dose,reward,next_sofa, done)\n",
        "\n",
        "        if verbose:\n",
        "            print(transition)\n",
        "\n",
        "        # update Q(S,A) using TD(0)\n",
        "        # Q(S,A) = Q(S,A) + alpha (r + gamma * max_a Q(S',a) - Q(S,A))\n",
        "        Q[sofa_level,vaso_dose] += alpha*(reward+gamma*np.amax(Q[next_sofa,:])-Q[sofa_level,vaso_dose])\n",
        "\n",
        "        sofa_level = next_sofa # update sofa for next iteration\n",
        "\n",
        "        # terminal state check\n",
        "        if next_sofa == terminal_state:\n",
        "            done = True\n",
        "            break\n",
        "    if ep % 10 == 0:\n",
        "        print('Q \\n', Q)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbhl5r9ppNu"
      },
      "source": [
        "**Exercise 1**\n",
        "\n",
        "If the agent is in state 0, what is the most valuable action? what is least valuable action? Enter your final Q estimate here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo5YKWiZppNu"
      },
      "source": [
        "When in state 1, the most valuable action is between giving a dosage of 3 or 4. The lease valuable action is giving a dosage of 2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "id": "8GTU56tfrwCn",
        "outputId": "69f76803-e325-4f52-bd04-8f410cb4d467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 990.000,  982.315,  985.188,  1000.000,  1000.000],\n",
              "       [ 967.268,  976.012,  979.938,  992.796,  1000.000],\n",
              "       [-74.660,  841.440,  853.276,  990.000,  887.668],\n",
              "       [ 0.000,  0.000,  0.000,  0.000,  0.000]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knw6QSqOppNu"
      },
      "source": [
        "**Exercise 2**\n",
        "\n",
        "How do your answers change with different $\\alpha$? different $\\epsilon$? Enter your final Q estimates here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rH60PvZIppNu",
        "outputId": "faf8d4dc-0995-47ad-df5c-93c2e59b8001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 1\n",
            "Q \n",
            " [[ 1.704  0.608  0.520 -0.870  1.627]\n",
            " [-2.324  1.354 -1.146 -1.972 -0.195]\n",
            " [-30.204 -2.390 -0.416 -0.746 -0.750]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 11\n",
            "Q \n",
            " [[ 654.053  591.254  621.730  625.148  692.543]\n",
            " [ 347.188  544.763  499.109  370.976  685.833]\n",
            " [-88.269  633.767  400.935  287.360  220.646]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 21\n",
            "Q \n",
            " [[ 882.578  856.642  853.482  892.148  907.840]\n",
            " [ 783.707  835.078  768.136  672.349  906.696]\n",
            " [-97.183  837.732  734.463  683.807  786.023]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 31\n",
            "Q \n",
            " [[ 964.936  957.260  950.200  975.106  977.816]\n",
            " [ 884.291  916.693  951.505  851.406  976.782]\n",
            " [-99.034  924.382  817.910  924.367  961.765]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 41\n",
            "Q \n",
            " [[ 982.222  974.199  973.744  993.292  994.628]\n",
            " [ 958.706  959.443  959.973  956.835  994.444]\n",
            " [-99.838  962.234  936.924  924.367  983.705]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 51\n",
            "Q \n",
            " [[ 988.342  976.865  975.797  998.321  998.451]\n",
            " [ 966.357  968.054  979.235  996.016  998.422]\n",
            " [-99.973  964.856  951.725  924.367  988.296]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 61\n",
            "Q \n",
            " [[ 989.615  982.989  978.374  999.600  999.684]\n",
            " [ 968.863  984.447  979.694  999.384  999.665]\n",
            " [-99.991  972.216  962.930  984.040  989.610]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 71\n",
            "Q \n",
            " [[ 989.919  977.097  981.118  999.924  999.932]\n",
            " [ 969.943  984.674  981.934  999.867  999.929]\n",
            " [-99.998  976.507  977.675  988.870  989.916]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 81\n",
            "Q \n",
            " [[ 989.985  982.796  975.894  999.985  999.986]\n",
            " [ 970.074  979.565  980.643  999.965  999.986]\n",
            " [-99.999  973.215  979.783  989.204  989.985]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 91\n",
            "Q \n",
            " [[ 989.995  978.352  972.669  999.995  999.996]\n",
            " [ 970.091  987.333  977.418  999.986  999.996]\n",
            " [-100.000  982.199  980.520  989.607  989.995]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 101\n",
            "Q \n",
            " [[ 989.999  979.311  979.971  999.999  999.999]\n",
            " [ 970.097  984.717  981.463  999.998  999.999]\n",
            " [-100.000  980.206  981.175  989.806  989.999]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 111\n",
            "Q \n",
            " [[ 990.000  979.432  973.570  1000.000  1000.000]\n",
            " [ 970.099  980.669  977.937  1000.000  1000.000]\n",
            " [-100.000  981.874  981.654  989.977  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 121\n",
            "Q \n",
            " [[ 990.000  977.877  977.475  1000.000  1000.000]\n",
            " [ 970.100  978.287  977.361  1000.000  1000.000]\n",
            " [-100.000  974.536  981.731  989.998  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 131\n",
            "Q \n",
            " [[ 990.000  980.843  976.422  1000.000  1000.000]\n",
            " [ 970.100  972.497  976.634  1000.000  1000.000]\n",
            " [-100.000  980.297  980.060  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 141\n",
            "Q \n",
            " [[ 990.000  982.213  983.145  1000.000  1000.000]\n",
            " [ 970.100  979.052  978.829  1000.000  1000.000]\n",
            " [-100.000  975.096  983.434  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 151\n",
            "Q \n",
            " [[ 990.000  974.489  981.624  1000.000  1000.000]\n",
            " [ 970.100  987.361  980.671  1000.000  1000.000]\n",
            " [-100.000  981.963  986.791  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 161\n",
            "Q \n",
            " [[ 990.000  971.468  980.797  1000.000  1000.000]\n",
            " [ 970.100  986.922  978.354  1000.000  1000.000]\n",
            " [-100.000  974.141  988.027  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 171\n",
            "Q \n",
            " [[ 990.000  982.215  985.917  1000.000  1000.000]\n",
            " [ 970.100  977.550  972.975  1000.000  1000.000]\n",
            " [-100.000  974.060  982.422  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 181\n",
            "Q \n",
            " [[ 990.000  985.646  983.277  1000.000  1000.000]\n",
            " [ 970.100  972.455  978.601  1000.000  1000.000]\n",
            " [-100.000  980.354  980.087  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 191\n",
            "Q \n",
            " [[ 990.000  986.649  978.670  1000.000  1000.000]\n",
            " [ 970.100  974.746  975.887  1000.000  1000.000]\n",
            " [-100.000  977.278  981.393  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 201\n",
            "Q \n",
            " [[ 990.000  973.419  981.091  1000.000  1000.000]\n",
            " [ 970.100  975.665  978.799  1000.000  1000.000]\n",
            " [-100.000  978.411  976.899  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 211\n",
            "Q \n",
            " [[ 990.000  988.868  982.169  1000.000  1000.000]\n",
            " [ 970.100  982.706  976.754  1000.000  1000.000]\n",
            " [-100.000  980.142  979.401  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 221\n",
            "Q \n",
            " [[ 990.000  974.069  974.062  1000.000  1000.000]\n",
            " [ 970.100  973.150  984.023  1000.000  1000.000]\n",
            " [-100.000  978.481  985.198  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 231\n",
            "Q \n",
            " [[ 990.000  981.292  976.614  1000.000  1000.000]\n",
            " [ 970.100  977.380  978.667  1000.000  1000.000]\n",
            " [-100.000  980.177  980.829  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 241\n",
            "Q \n",
            " [[ 990.000  979.713  979.708  1000.000  1000.000]\n",
            " [ 970.100  985.333  980.930  1000.000  1000.000]\n",
            " [-100.000  982.204  983.581  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 251\n",
            "Q \n",
            " [[ 990.000  985.987  974.020  1000.000  1000.000]\n",
            " [ 970.100  979.015  980.351  1000.000  1000.000]\n",
            " [-100.000  978.431  977.516  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 261\n",
            "Q \n",
            " [[ 990.000  974.543  975.331  1000.000  1000.000]\n",
            " [ 970.100  975.185  985.983  1000.000  1000.000]\n",
            " [-100.000  978.927  981.033  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 271\n",
            "Q \n",
            " [[ 990.000  971.872  981.531  1000.000  1000.000]\n",
            " [ 970.100  979.949  988.490  1000.000  1000.000]\n",
            " [-100.000  984.574  984.079  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 281\n",
            "Q \n",
            " [[ 990.000  983.396  973.842  1000.000  1000.000]\n",
            " [ 970.100  980.482  979.977  1000.000  1000.000]\n",
            " [-100.000  981.621  979.927  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 291\n",
            "Q \n",
            " [[ 990.000  977.101  985.555  1000.000  1000.000]\n",
            " [ 970.100  982.654  978.975  1000.000  1000.000]\n",
            " [-100.000  975.517  976.979  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 301\n",
            "Q \n",
            " [[ 990.000  984.841  975.342  1000.000  1000.000]\n",
            " [ 970.100  984.857  972.967  1000.000  1000.000]\n",
            " [-100.000  978.725  985.534  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 311\n",
            "Q \n",
            " [[ 990.000  985.601  971.988  1000.000  1000.000]\n",
            " [ 970.100  979.240  974.940  1000.000  1000.000]\n",
            " [-100.000  976.137  977.663  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 321\n",
            "Q \n",
            " [[ 990.000  976.052  973.499  1000.000  1000.000]\n",
            " [ 970.100  980.481  985.161  1000.000  1000.000]\n",
            " [-100.000  979.028  981.364  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 331\n",
            "Q \n",
            " [[ 990.000  980.801  987.681  1000.000  1000.000]\n",
            " [ 970.100  983.268  982.370  1000.000  1000.000]\n",
            " [-100.000  984.624  987.926  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 341\n",
            "Q \n",
            " [[ 990.000  975.789  980.085  1000.000  1000.000]\n",
            " [ 970.100  977.924  975.186  1000.000  1000.000]\n",
            " [-100.000  987.366  980.393  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 351\n",
            "Q \n",
            " [[ 990.000  979.905  987.048  1000.000  1000.000]\n",
            " [ 970.100  973.946  977.361  1000.000  1000.000]\n",
            " [-100.000  980.201  971.830  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 361\n",
            "Q \n",
            " [[ 990.000  984.142  983.969  1000.000  1000.000]\n",
            " [ 970.100  977.954  982.957  1000.000  1000.000]\n",
            " [-100.000  977.744  985.637  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 371\n",
            "Q \n",
            " [[ 990.000  975.644  982.101  1000.000  1000.000]\n",
            " [ 970.100  976.165  980.047  1000.000  1000.000]\n",
            " [-100.000  981.421  976.756  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 381\n",
            "Q \n",
            " [[ 990.000  987.896  977.695  1000.000  1000.000]\n",
            " [ 970.100  977.040  982.308  1000.000  1000.000]\n",
            " [-100.000  987.057  976.671  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 391\n",
            "Q \n",
            " [[ 990.000  983.412  978.824  1000.000  1000.000]\n",
            " [ 970.100  979.735  983.330  1000.000  1000.000]\n",
            " [-100.000  981.886  977.499  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 401\n",
            "Q \n",
            " [[ 990.000  984.715  973.799  1000.000  1000.000]\n",
            " [ 970.100  975.718  978.463  1000.000  1000.000]\n",
            " [-100.000  975.875  975.563  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 411\n",
            "Q \n",
            " [[ 990.000  983.160  986.430  1000.000  1000.000]\n",
            " [ 970.100  981.373  974.565  1000.000  1000.000]\n",
            " [-100.000  984.003  982.926  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 421\n",
            "Q \n",
            " [[ 990.000  985.928  978.554  1000.000  1000.000]\n",
            " [ 970.100  974.682  986.440  1000.000  1000.000]\n",
            " [-100.000  980.142  976.385  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 431\n",
            "Q \n",
            " [[ 990.000  979.304  977.675  1000.000  1000.000]\n",
            " [ 970.100  972.500  978.550  1000.000  1000.000]\n",
            " [-100.000  976.470  980.469  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 441\n",
            "Q \n",
            " [[ 990.000  979.882  973.970  1000.000  1000.000]\n",
            " [ 970.100  983.591  979.978  1000.000  1000.000]\n",
            " [-100.000  976.470  975.181  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 451\n",
            "Q \n",
            " [[ 990.000  984.440  973.070  1000.000  1000.000]\n",
            " [ 970.100  976.342  978.574  1000.000  1000.000]\n",
            " [-100.000  971.629  971.843  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 461\n",
            "Q \n",
            " [[ 990.000  984.684  976.332  1000.000  1000.000]\n",
            " [ 970.100  977.663  973.534  1000.000  1000.000]\n",
            " [-100.000  976.686  986.860  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 471\n",
            "Q \n",
            " [[ 990.000  977.391  974.785  1000.000  1000.000]\n",
            " [ 970.100  984.671  978.695  1000.000  1000.000]\n",
            " [-100.000  984.505  980.094  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 481\n",
            "Q \n",
            " [[ 990.000  981.456  977.234  1000.000  1000.000]\n",
            " [ 970.100  974.865  981.010  1000.000  1000.000]\n",
            " [-100.000  983.708  983.066  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 491\n",
            "Q \n",
            " [[ 990.000  979.596  975.565  1000.000  1000.000]\n",
            " [ 970.100  978.744  982.519  1000.000  1000.000]\n",
            " [-100.000  986.334  986.602  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
        "\n",
        "# Initialize states, actions, Q function\n",
        "\n",
        "# states\n",
        "sofa_levels = [0,1,2,3]\n",
        "num_states = len(sofa_levels)\n",
        "terminal_state = 3\n",
        "\n",
        "# actions\n",
        "vaso_dose = [0,1,2,3,4]\n",
        "num_actions = len(vaso_dose)\n",
        "\n",
        "# initialize array to store action values Q\n",
        "Q = np.random.normal(size=(num_states, num_actions))\n",
        "Q[terminal_state,:] = 0 # no action taken from terminal state, so no value\n",
        "\n",
        "\n",
        "def act(epsilon, action_values):\n",
        "    '''\n",
        "    epsilon-greedy policy: return action using epsilon-greedy strategy\n",
        "    '''\n",
        "    action_size = len(action_values)\n",
        "    if np.random.rand() <= epsilon: # random draw with prob epsilon\n",
        "        return random.randrange(action_size)\n",
        "    return np.argmax(action_values)  # returns action\n",
        "\n",
        "def calc_reward(state):\n",
        "    '''\n",
        "    simple reward function for illustration. lower state value is better\n",
        "    '''\n",
        "    if state == 3:\n",
        "        reward = -100\n",
        "    elif state == 2:\n",
        "        reward = -10\n",
        "    elif state == 1:\n",
        "        reward = 0\n",
        "    else:\n",
        "        reward = 10\n",
        "    return reward\n",
        "\n",
        "def determine_next_state(state, action):\n",
        "    '''\n",
        "    return next state from the environment\n",
        "    to be replaced with simulated data or alternative\n",
        "    '''\n",
        "    if (state in [0,1,2]) & (action == 0): # no dose raises state\n",
        "        next_state = min(terminal_state, state + 1)\n",
        "    elif action in [3,4]: # higher doses lowers state (floored at zero)\n",
        "        next_state = max(0, state - 1)\n",
        "    else:\n",
        "        next_state = random.choice([1,2])\n",
        "    return next_state\n",
        "\n",
        "# Run the Process\n",
        "num_episodes = 500\n",
        "max_timesteps = 100\n",
        "epsilon = 0.3\n",
        "alpha = 0.3 # weight on new data\n",
        "gamma = 0.99 # discount factor\n",
        "verbose = False\n",
        "\n",
        "for ep in range(num_episodes):\n",
        "    if ep % 10 == 0:\n",
        "        print('episode',ep+1)\n",
        "    #print('(state,action,reward,next_state) transitions')\n",
        "    sofa_level = 0 # initialize state\n",
        "    done = False\n",
        "    for tm in range(max_timesteps):\n",
        "\n",
        "        # given state, get action from policy\n",
        "        vaso_dose = act(epsilon, Q[sofa_level,:])\n",
        "\n",
        "        next_sofa = determine_next_state(sofa_level, vaso_dose)\n",
        "        reward = calc_reward(next_sofa)\n",
        "        transition = (sofa_level,vaso_dose,reward,next_sofa, done)\n",
        "\n",
        "        if verbose:\n",
        "            print(transition)\n",
        "\n",
        "        # update Q(S,A) using TD(0)\n",
        "        # Q(S,A) = Q(S,A) + alpha (r + gamma * max_a Q(S',a) - Q(S,A))\n",
        "        Q[sofa_level,vaso_dose] += alpha*(reward+gamma*np.amax(Q[next_sofa,:])-Q[sofa_level,vaso_dose])\n",
        "\n",
        "        sofa_level = next_sofa # update sofa for next iteration\n",
        "\n",
        "        # terminal state check\n",
        "        if next_sofa == terminal_state:\n",
        "            done = True\n",
        "            break\n",
        "    if ep % 10 == 0:\n",
        "        print('Q \\n', Q)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "id": "ojJ25j3uvizB",
        "outputId": "c0911946-41e2-46a4-87ab-e00da0a700d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 990.000,  979.321,  984.202,  1000.000,  1000.000],\n",
              "       [ 970.100,  971.643,  981.977,  1000.000,  1000.000],\n",
              "       [-100.000,  988.204,  986.504,  990.000,  990.000],\n",
              "       [ 0.000,  0.000,  0.000,  0.000,  0.000]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing alpha and epsilon to 0.2 instead of 0.1, the optimal dosage is still either 3 or 4, but the worst dosage is now 1. It was close between 1 and 2 again though. Also converges faster."
      ],
      "metadata": {
        "id": "nGNZJ5KosRJL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLh4sMeVppNu"
      },
      "source": [
        "**Exercise 3**\n",
        "\n",
        "We initialized Q with standard normal deviates. How do your answers in (1) change if you initialize Q with zeros?  \n",
        "Enter your final Q estimates here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PKEbixmyppNu",
        "outputId": "c02ee137-2a3f-4f10-8e29-a50616bd43c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 1\n",
            "Q \n",
            " [[ 0.000  0.000  0.000  0.000  0.000]\n",
            " [-3.000  0.000  0.000  0.000  0.000]\n",
            " [-30.000  0.000  0.000  0.000  0.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 11\n",
            "Q \n",
            " [[ 660.964  597.726  638.766  717.199  664.510]\n",
            " [ 341.218  500.433  375.451  703.695  252.176]\n",
            " [-91.765  448.751  231.209  672.253  410.354]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 21\n",
            "Q \n",
            " [[ 914.171  900.305  904.681  933.142  924.584]\n",
            " [ 797.950  796.476  874.986  931.560  826.807]\n",
            " [-98.023  714.785  716.138  916.275  663.926]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 31\n",
            "Q \n",
            " [[ 960.917  947.901  960.002  975.710  972.910]\n",
            " [ 919.177  888.930  928.414  974.922  963.027]\n",
            " [-99.668  832.437  847.855  961.912  852.714]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 41\n",
            "Q \n",
            " [[ 983.984  967.419  974.944  994.721  993.924]\n",
            " [ 956.565  972.893  969.741  994.568  989.405]\n",
            " [-99.837  902.953  939.409  984.220  935.022]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 51\n",
            "Q \n",
            " [[ 988.436  974.816  977.142  998.725  998.529]\n",
            " [ 966.643  971.828  973.132  998.674  998.107]\n",
            " [-99.961  954.052  968.495  988.523  978.981]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 61\n",
            "Q \n",
            " [[ 989.685  986.967  980.621  999.730  999.696]\n",
            " [ 969.626  979.490  982.928  999.718  999.569]\n",
            " [-99.981  972.975  973.074  989.684  981.995]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 71\n",
            "Q \n",
            " [[ 989.891  984.589  978.366  999.918  999.904]\n",
            " [ 969.920  976.503  984.101  999.917  999.881]\n",
            " [-99.995  971.452  970.708  989.910  987.970]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 81\n",
            "Q \n",
            " [[ 989.982  983.968  981.055  999.983  999.981]\n",
            " [ 970.066  981.983  984.761  999.983  999.975]\n",
            " [-99.997  985.518  970.384  989.980  989.270]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 91\n",
            "Q \n",
            " [[ 989.995  987.716  985.266  999.996  999.996]\n",
            " [ 970.083  984.468  983.896  999.996  999.993]\n",
            " [-99.999  986.859  970.384  989.994  989.638]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 101\n",
            "Q \n",
            " [[ 989.999  975.268  978.924  999.999  999.999]\n",
            " [ 970.098  987.914  973.706  999.999  999.999]\n",
            " [-100.000  987.800  980.345  989.999  989.938]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 111\n",
            "Q \n",
            " [[ 990.000  977.072  970.791  1000.000  1000.000]\n",
            " [ 970.099  985.517  971.856  1000.000  1000.000]\n",
            " [-100.000  973.399  986.688  990.000  989.989]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 121\n",
            "Q \n",
            " [[ 990.000  974.041  980.589  1000.000  1000.000]\n",
            " [ 970.100  983.660  987.992  1000.000  1000.000]\n",
            " [-100.000  974.157  977.234  990.000  989.996]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 131\n",
            "Q \n",
            " [[ 990.000  976.914  986.824  1000.000  1000.000]\n",
            " [ 970.100  983.505  983.770  1000.000  1000.000]\n",
            " [-100.000  978.058  981.442  990.000  989.999]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 141\n",
            "Q \n",
            " [[ 990.000  980.501  979.007  1000.000  1000.000]\n",
            " [ 970.100  985.279  983.277  1000.000  1000.000]\n",
            " [-100.000  981.641  977.796  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 151\n",
            "Q \n",
            " [[ 990.000  980.839  984.746  1000.000  1000.000]\n",
            " [ 970.100  984.719  978.442  1000.000  1000.000]\n",
            " [-100.000  980.889  981.457  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 161\n",
            "Q \n",
            " [[ 990.000  980.550  982.530  1000.000  1000.000]\n",
            " [ 970.100  985.807  971.924  1000.000  1000.000]\n",
            " [-100.000  986.421  988.609  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 171\n",
            "Q \n",
            " [[ 990.000  986.718  974.406  1000.000  1000.000]\n",
            " [ 970.100  979.475  973.020  1000.000  1000.000]\n",
            " [-100.000  979.070  980.871  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 181\n",
            "Q \n",
            " [[ 990.000  976.917  975.009  1000.000  1000.000]\n",
            " [ 970.100  983.509  983.960  1000.000  1000.000]\n",
            " [-100.000  976.379  980.899  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 191\n",
            "Q \n",
            " [[ 990.000  982.796  983.092  1000.000  1000.000]\n",
            " [ 970.100  986.145  977.768  1000.000  1000.000]\n",
            " [-100.000  974.495  978.663  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 201\n",
            "Q \n",
            " [[ 990.000  973.573  978.560  1000.000  1000.000]\n",
            " [ 970.100  983.140  979.710  1000.000  1000.000]\n",
            " [-100.000  979.147  978.663  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 211\n",
            "Q \n",
            " [[ 990.000  979.048  980.089  1000.000  1000.000]\n",
            " [ 970.100  987.414  982.298  1000.000  1000.000]\n",
            " [-100.000  986.277  976.335  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 221\n",
            "Q \n",
            " [[ 990.000  987.807  976.348  1000.000  1000.000]\n",
            " [ 970.100  982.220  985.225  1000.000  1000.000]\n",
            " [-100.000  978.027  977.334  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 231\n",
            "Q \n",
            " [[ 990.000  977.710  984.695  1000.000  1000.000]\n",
            " [ 970.100  973.963  976.622  1000.000  1000.000]\n",
            " [-100.000  975.649  975.164  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 241\n",
            "Q \n",
            " [[ 990.000  975.044  973.747  1000.000  1000.000]\n",
            " [ 970.100  975.206  976.836  1000.000  1000.000]\n",
            " [-100.000  975.649  975.164  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 251\n",
            "Q \n",
            " [[ 990.000  983.120  980.475  1000.000  1000.000]\n",
            " [ 970.100  981.534  979.123  1000.000  1000.000]\n",
            " [-100.000  985.078  975.495  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 261\n",
            "Q \n",
            " [[ 990.000  977.694  983.625  1000.000  1000.000]\n",
            " [ 970.100  979.682  983.199  1000.000  1000.000]\n",
            " [-100.000  981.207  984.985  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 271\n",
            "Q \n",
            " [[ 990.000  978.111  975.226  1000.000  1000.000]\n",
            " [ 970.100  979.340  979.472  1000.000  1000.000]\n",
            " [-100.000  978.089  980.519  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 281\n",
            "Q \n",
            " [[ 990.000  981.411  976.014  1000.000  1000.000]\n",
            " [ 970.100  981.862  982.004  1000.000  1000.000]\n",
            " [-100.000  978.245  983.364  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 291\n",
            "Q \n",
            " [[ 990.000  976.157  983.937  1000.000  1000.000]\n",
            " [ 970.100  979.501  975.883  1000.000  1000.000]\n",
            " [-100.000  975.819  986.359  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 301\n",
            "Q \n",
            " [[ 990.000  977.270  981.913  1000.000  1000.000]\n",
            " [ 970.100  975.233  981.638  1000.000  1000.000]\n",
            " [-100.000  976.446  979.856  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 311\n",
            "Q \n",
            " [[ 990.000  983.838  987.385  1000.000  1000.000]\n",
            " [ 970.100  978.067  978.162  1000.000  1000.000]\n",
            " [-100.000  974.542  983.595  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 321\n",
            "Q \n",
            " [[ 990.000  970.991  972.382  1000.000  1000.000]\n",
            " [ 970.100  978.354  974.111  1000.000  1000.000]\n",
            " [-100.000  982.205  986.862  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 331\n",
            "Q \n",
            " [[ 990.000  981.991  984.605  1000.000  1000.000]\n",
            " [ 970.100  980.035  973.638  1000.000  1000.000]\n",
            " [-100.000  982.001  974.965  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 341\n",
            "Q \n",
            " [[ 990.000  980.687  977.460  1000.000  1000.000]\n",
            " [ 970.100  984.909  973.875  1000.000  1000.000]\n",
            " [-100.000  986.081  973.505  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 351\n",
            "Q \n",
            " [[ 990.000  981.754  974.604  1000.000  1000.000]\n",
            " [ 970.100  976.861  984.439  1000.000  1000.000]\n",
            " [-100.000  974.834  972.484  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 361\n",
            "Q \n",
            " [[ 990.000  977.921  983.630  1000.000  1000.000]\n",
            " [ 970.100  977.043  977.399  1000.000  1000.000]\n",
            " [-100.000  976.598  982.092  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 371\n",
            "Q \n",
            " [[ 990.000  983.215  986.117  1000.000  1000.000]\n",
            " [ 970.100  974.475  980.111  1000.000  1000.000]\n",
            " [-100.000  978.299  986.125  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 381\n",
            "Q \n",
            " [[ 990.000  975.401  984.612  1000.000  1000.000]\n",
            " [ 970.100  979.356  974.687  1000.000  1000.000]\n",
            " [-100.000  987.191  987.022  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 391\n",
            "Q \n",
            " [[ 990.000  977.704  982.418  1000.000  1000.000]\n",
            " [ 970.100  977.159  981.094  1000.000  1000.000]\n",
            " [-100.000  984.444  983.315  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 401\n",
            "Q \n",
            " [[ 990.000  976.589  987.046  1000.000  1000.000]\n",
            " [ 970.100  976.425  978.966  1000.000  1000.000]\n",
            " [-100.000  987.278  977.452  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 411\n",
            "Q \n",
            " [[ 990.000  973.019  982.257  1000.000  1000.000]\n",
            " [ 970.100  971.228  980.804  1000.000  1000.000]\n",
            " [-100.000  981.962  984.410  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 421\n",
            "Q \n",
            " [[ 990.000  973.879  978.121  1000.000  1000.000]\n",
            " [ 970.100  984.656  985.291  1000.000  1000.000]\n",
            " [-100.000  977.094  981.291  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 431\n",
            "Q \n",
            " [[ 990.000  977.978  980.113  1000.000  1000.000]\n",
            " [ 970.100  980.411  980.864  1000.000  1000.000]\n",
            " [-100.000  978.884  982.566  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 441\n",
            "Q \n",
            " [[ 990.000  971.149  987.960  1000.000  1000.000]\n",
            " [ 970.100  983.510  977.451  1000.000  1000.000]\n",
            " [-100.000  973.113  984.525  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 451\n",
            "Q \n",
            " [[ 990.000  978.839  985.336  1000.000  1000.000]\n",
            " [ 970.100  986.800  983.341  1000.000  1000.000]\n",
            " [-100.000  988.609  973.563  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 461\n",
            "Q \n",
            " [[ 990.000  983.697  974.971  1000.000  1000.000]\n",
            " [ 970.100  981.790  981.477  1000.000  1000.000]\n",
            " [-100.000  974.544  971.288  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 471\n",
            "Q \n",
            " [[ 990.000  974.493  980.628  1000.000  1000.000]\n",
            " [ 970.100  984.061  983.686  1000.000  1000.000]\n",
            " [-100.000  975.206  974.861  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 481\n",
            "Q \n",
            " [[ 990.000  977.058  982.568  1000.000  1000.000]\n",
            " [ 970.100  978.501  975.864  1000.000  1000.000]\n",
            " [-100.000  983.523  984.317  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n",
            "episode 491\n",
            "Q \n",
            " [[ 990.000  975.894  972.624  1000.000  1000.000]\n",
            " [ 970.100  976.554  981.398  1000.000  1000.000]\n",
            " [-100.000  982.647  979.156  990.000  990.000]\n",
            " [ 0.000  0.000  0.000  0.000  0.000]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
        "\n",
        "# Initialize states, actions, Q function\n",
        "\n",
        "# states\n",
        "sofa_levels = [0,1,2,3]\n",
        "num_states = len(sofa_levels)\n",
        "terminal_state = 3\n",
        "\n",
        "# actions\n",
        "vaso_dose = [0,1,2,3,4]\n",
        "num_actions = len(vaso_dose)\n",
        "\n",
        "# initialize array to store action values Q\n",
        "Q = np.zeros(shape=(num_states, num_actions))\n",
        "Q[terminal_state,:] = 0 # no action taken from terminal state, so no value\n",
        "\n",
        "\n",
        "def act(epsilon, action_values):\n",
        "    '''\n",
        "    epsilon-greedy policy: return action using epsilon-greedy strategy\n",
        "    '''\n",
        "    action_size = len(action_values)\n",
        "    if np.random.rand() <= epsilon: # random draw with prob epsilon\n",
        "        return random.randrange(action_size)\n",
        "    return np.argmax(action_values)  # returns action\n",
        "\n",
        "def calc_reward(state):\n",
        "    '''\n",
        "    simple reward function for illustration. lower state value is better\n",
        "    '''\n",
        "    if state == 3:\n",
        "        reward = -100\n",
        "    elif state == 2:\n",
        "        reward = -10\n",
        "    elif state == 1:\n",
        "        reward = 0\n",
        "    else:\n",
        "        reward = 10\n",
        "    return reward\n",
        "\n",
        "def determine_next_state(state, action):\n",
        "    '''\n",
        "    return next state from the environment\n",
        "    to be replaced with simulated data or alternative\n",
        "    '''\n",
        "    if (state in [0,1,2]) & (action == 0): # no dose raises state\n",
        "        next_state = min(terminal_state, state + 1)\n",
        "    elif action in [3,4]: # higher doses lowers state (floored at zero)\n",
        "        next_state = max(0, state - 1)\n",
        "    else:\n",
        "        next_state = random.choice([1,2])\n",
        "    return next_state\n",
        "\n",
        "# Run the Process\n",
        "num_episodes = 500\n",
        "max_timesteps = 100\n",
        "epsilon = 0.3\n",
        "alpha = 0.3 # weight on new data\n",
        "gamma = 0.99 # discount factor\n",
        "verbose = False\n",
        "\n",
        "for ep in range(num_episodes):\n",
        "    if ep % 10 == 0:\n",
        "        print('episode',ep+1)\n",
        "    #print('(state,action,reward,next_state) transitions')\n",
        "    sofa_level = 0 # initialize state\n",
        "    done = False\n",
        "    for tm in range(max_timesteps):\n",
        "\n",
        "        # given state, get action from policy\n",
        "        vaso_dose = act(epsilon, Q[sofa_level,:])\n",
        "\n",
        "        next_sofa = determine_next_state(sofa_level, vaso_dose)\n",
        "        reward = calc_reward(next_sofa)\n",
        "        transition = (sofa_level,vaso_dose,reward,next_sofa, done)\n",
        "\n",
        "        if verbose:\n",
        "            print(transition)\n",
        "\n",
        "        # update Q(S,A) using TD(0)\n",
        "        # Q(S,A) = Q(S,A) + alpha (r + gamma * max_a Q(S',a) - Q(S,A))\n",
        "        Q[sofa_level,vaso_dose] += alpha*(reward+gamma*np.amax(Q[next_sofa,:])-Q[sofa_level,vaso_dose])\n",
        "\n",
        "        sofa_level = next_sofa # update sofa for next iteration\n",
        "\n",
        "        # terminal state check\n",
        "        if next_sofa == terminal_state:\n",
        "            done = True\n",
        "            break\n",
        "    if ep % 10 == 0:\n",
        "        print('Q \\n', Q)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "id": "rPXOXhY4u1x8",
        "outputId": "cbde23ed-8612-4ce1-8a71-503ddfa42f1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 990.000,  982.168,  979.743,  1000.000,  1000.000],\n",
              "       [ 970.100,  980.337,  988.950,  1000.000,  1000.000],\n",
              "       [-100.000,  979.339,  979.156,  990.000,  990.000],\n",
              "       [ 0.000,  0.000,  0.000,  0.000,  0.000]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The answers didn't seem to change, maybe didn't converge as quick."
      ],
      "metadata": {
        "id": "I1eTD9maubCR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-C7zz4zppNu"
      },
      "source": [
        "**Exercise 4**\n",
        "\n",
        "Does Q seem to converge? It will converge given enough iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code does seem to converge at different rates."
      ],
      "metadata": {
        "id": "CjPiTKPbvpcd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksqUY911ppNu"
      },
      "source": [
        "**Exercise 5**\n",
        "\n",
        "Modify the code to return all transitions as a list of tuples. Paste the first 10 transitions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kvTsaAeDppNu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf-wxfA6ppNv"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOU3QtspppNv"
      },
      "source": [
        "### III. Limitations of Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfjHP8pZppNv"
      },
      "source": [
        "As we've learned, Q-learning involves storing and updating a table or array of values $Q(S,A)$ where each element represents the value of a *(state,action)* tuple. This is called a *Q table*.\n",
        "\n",
        "**As the number of states and actions (the *state-action space*) grows, this approach becomes unmanageable** in terms of both storage and computation. This occurs for continuous variables or discrete variables with a massive number of possible values.\n",
        "\n",
        "There are two approaches to handle this issue:\n",
        "\n",
        "- Quantize the values\n",
        "\n",
        "For example, medication doses might be bucketed into dose ranges  \n",
        "\n",
        "- Function approximators for Q  \n",
        "\n",
        "The function approximation is now very popular, with neural nets playing a major role.\n",
        "\n",
        "**Going Deep**\n",
        "\n",
        "When deep neural networks are used with Q-Learning, the model is called a *Deep Q-Network*. We will study these next.\n",
        "\n",
        "In general, pairing reinforcement learning with a deep neural network is called *Deep Reinforcement Learning*, abbreviated Deep RL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JdWKPMpppNv"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}